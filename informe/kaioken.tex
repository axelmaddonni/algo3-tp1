\subsection{Explicación formal del problema}

\subsection{Explicación de la solución}

\subsection{Complejidad del algoritmo}

El análisis de complejidad es simple, es un algoritmo de Divide \& Conquer clásico, que divide siempre el trabajo en 2 y luego fusiona los resultados de los subproblemas en tiempo $O(n)$. Haciendo una analogía, por ejemplo, con el algoritmo de MergeSort, se puede predecir fácilmente que la complejidad será de $O(nlogn)$.

\subsubsection{Esbozo del algoritmo}

El algoritmo fue analizado en profundidad anteriormente. A grandes rasgos, puede describirse de la siguiente manera:
\begin{algorithm}
\begin{algorithmic}
\caption{Esbozo del algoritmo de KaioKen}
  \Procedure{generarpeleas}{int $n$, int $pactual$, int $inicio$}
  \If {$n = 1$}
    \State $matrizpeleas[pactual][inicio] \gets 1$
  \EndIf
  \If {$n = 2$}
    \State $matrizpeleas[pactual][inicio] \gets 1$
    \State $matrizpeleas[pactual][inicio + 1] \gets 2$
  \Else
    \For {$j \in [0,..., n)$}
      \If {$j < \frac{n}{2}$}
        \State $matrizpeleas[pactual][inicio + j] \gets 1$
      \Else 
        \State $matrizpeleas[pactual][inicio + j] \gets 2$
      \EndIf
    \EndFor
    \State $generarpeleas(\frac{n}{2}, pactual+1, inicio)$
    \State $generarpeleas(\frac{n+1}{2}, pactual+1, n/2 + inicio)$
  \EndIf
  \EndProcedure
\end{algorithmic}
\end{algorithm}

Como puede verse claramente, tenemos dos casos base que toman tiempo constante en ser resueltos.

Por otro lado, el tercer caso realiza un trabajo de costo lineal, escribiendo $n$ entradas de la matriz, y luego hace 2 llamadas recursivas, dividiendo el trabajo en 2 mitades iguales (en caso de que $n$ sea impar, la segunda mitad va a tener un elemento más).

\subsubsection{Análisis temporal}
Si quisieramos expresar la cantidad de operaciones que realiza el algoritmo para un input de tamaño $n$, podriamos escribirlo fácilmente de la siguiente manera:
\[T(1) = 1\]
\[T(2) = 2\]
\[T(n) = n + 2 T \left(\frac{n}{2}\right)\]

Ahora podemos usar el teorema maestro. El teorema maestro se referia a relaciones de recurrencia de la pinta:

\[T(n) = f(n) + a T\left(\frac{n}{b}\right)\]

Y afirmaba, entre otras cosas, que si $f(n) \in O(n^c \log^k n)$ donde $c = \log_b a$, entonces $T(n) \in \Theta(n^c \log^{k+1} n)$. En este caso, se ve claramente que $f(n) = n \in O(n^1 \log^0 n)$, y además $1 = \log_2 2$, por lo que el teorema maestro se puede aplicar, y nos dice que

\[T(n) \in \Theta(n \log n)\]

La complejidad de este algoritmo es siempre $\Theta(n \log n)$, sin distinción entre casos, es decir, este algoritmo no tiene mejor o peor caso. La forma más clara de verlo es que el único input del problema es $n$, y no hay otro parámetro que pueda modificar su complejidad.

\subsection{Performance del algoritmo}

Como dijimos antes, la complejidad del algoritmo es siempre $\Theta(n \log n)$, sin distinción entre casos, por lo que el análisis de performance es simple.

Primero veamos que, en la práctica, la complejidad del algoritmo es efectivamente $\Theta(n \log n)$.

\begin{figure}[H]
 \centering
	\includegraphics[width=0.8\textwidth]{img/tiempos/kaioken3.pdf}
	\caption{\footnotesize Tiempo que toma el algoritmo en $\mu$s para una entrada de tamaño $n$.}
	\label{fig:kaioken-tiempos3}
\end{figure}

Se ve claramente en la figura \ref{fig:kaioken-tiempos3} que el tiempo que toma el algoritmo esta acotado por arriba y por debajo por $k n \log n$ para algun $k$, es decir, el algoritmo es $\Theta(n \log n)$.

Para hacer un análisis más fino e interesante, es necesario hacer un \emph{close-up} y ver las complejidades de mas cerca.

\begin{figure}[H]
 \centering
	\includegraphics[width=0.8\textwidth]{img/tiempos/kaioken1.pdf}
	\caption{\footnotesize Tiempo que toma el algoritmo en $\mu$s para una entrada de tamaño $n$.}
	\label{fig:kaioken-tiempos1}
\end{figure}

Como puede verse en la figura \ref{fig:kaioken-tiempos1}, el algoritmo claramente es $\Theta(n \log n)$, pero también puede observarse que hay \emph{saltos} de tiempo en algunos lugares. Se puede inferir fácilmente que estos saltos suceden en las entradas donde $n = 2^k + 1$ para algun $k$, es decir, cuando $n$ es una potencia de 2 más 1. Esto se debe a que, como fue explicado antes, la cantidad de peleas necesarias es $\lceil \log_2(n) \rceil$, entonces para todos los numeros entre dos potencias de 2, la cantidad de peleas requerida es la misma, pero luego de una potencia de 2 esta cantidad de peleas aumenta en 1. A esto se debe los saltos luego de las potencias de 2.

Para visualizar más claramente este hecho, realizamos el siguiente gráfico, en el que están marcadas las potencias de 2.

\begin{figure}[H]
 \centering
	\includegraphics[width=0.8\textwidth]{img/tiempos/kaioken2.pdf}
	\caption{\footnotesize Tiempo que toma el algoritmo en $\mu$s dividido $n\log n$para una entrada de tamaño $n$.}
	\label{fig:kaioken-tiempos2}
\end{figure}

Con la figura \ref{fig:kaioken-tiempos2} se confirma lo que dijimos anteriormente. Luego de cada potencia de 2, el tiempo aumenta, y luego baja lentamente, dado que la relacion tiempo - $n \log n$ se mantiene constante, pero $n$ aumenta, con lo cual la división se achica.


\subsubsection{M\'etodo de experimentación}

Para este problema es fue muy fácil generar casos de prueba, dado que el único input para el programa es $n$, por lo que simplemente corrimos el programa con diferentes $n$ de entrada. Ejecutamos el programa 50 veces para cada $n$ y el resultado que graficamos fue el mínimo de todas las ejecuciones (para cada $n$). Elegimos el mínimo porque es el que nos permite eliminar outliers que tienen que ver con context switches o con factores de la ejecucion sobre los que no tenemos control.


